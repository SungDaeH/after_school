{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are eight planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 13, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-74413f65-14fa-41c6-943b-5003b6d5ec15-0', usage_metadata={'input_tokens': 13, 'output_tokens': 27, 'total_tokens': 40})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How may planets art there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë„ˆëŠ” ì„¸ê³„ ìµœê³ ì˜ ë†ë‹´ê¾¼ì´ì•¼ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µ ë§ ëë§ˆë‹¤ ë†ë‹´ì„ í•´ì¤˜\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë„ˆë¬´ ëœ¨ê±°ì›Œì„œ ë‚´ ë†ë‹´ ì‹¤ë ¥ë„ ë…¹ì„ ê²ƒ ê°™ì•„! ğŸ˜„', response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 72, 'total_tokens': 117}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ff1b6517-52db-482e-abab-dd047eea823a-0', usage_metadata={'input_tokens': 72, 'output_tokens': 45, 'total_tokens': 117})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\" : \"ì•ˆë…•, ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë•Œ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì†ì¬ë§ˆ? ê·¸ê±´ ë­ì£ ? ì†ìœ¼ë¡œ ì¬ë¥¼ ë§Œë“œëŠ” ë§ë¼ê¹½ì´ë§ˆ? ì•„ë‹ˆë©´ ì†ìœ¼ë¡œ ë§ˆë²•ì„ ë¶€ë¦¬ëŠ” ìš”ìˆ ì‚¬ë§ˆ? í•˜í•˜í•˜!', response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 61, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7a74c7e1-739e-408d-86ea-ef54f9312389-0', usage_metadata={'input_tokens': 61, 'output_tokens': 58, 'total_tokens': 119})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"ì†ì¬ë§ˆ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
