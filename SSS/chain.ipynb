{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain과 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI() # text-davinch-003 <- llm이라고 칭함\n",
    "\n",
    "chat = ChatOpenAI() # Chat 에 ChatModel 할당\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 값이 높을수록 창의적인 답변을 함, (조금 더 인간답다.)\n",
    "    model='gpt-4' # OpenAI에서 제공하는 ChatModel을 바꿀 수 있다.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rladm\\SSS_langchain\\env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"hi\") # 예측, Chatmodel 에 질의의 결과를 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-19e93936-1dd0-4405-b275-fa610b94ca52-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke('hi') # 여러 상태, 세부정보를 표현, AIMessage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Parser\n",
    "\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(',')\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "    # strip : 문자열 공백 제거 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'World', 'hi', 'How', 'are', 'you?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = CommaOutputParser()\n",
    "\n",
    "parser.parse('Hello, World, hi, How, are, you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "# tuple\n",
    "    (\"system\", \"You are a list Generating machine. Everything you are asked will be ansered with a comma list of max {max_items}. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a list Generating machine. Everything you are asked will be ansered with a comma list of max 10. Do NOT reply with anything else.'),\n",
       " HumanMessage(content='What are the planets')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template.format_messages(\n",
    "    max_items = 10,\n",
    "    question = \"What are the planets\"\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseChatModel.predict_messages of ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000019D14767410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000019D14765B80>, model_name='gpt-4', temperature=0.1, openai_api_key=SecretStr('**********'), openai_proxy='')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat.predict_messages\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m parser \u001b[38;5;241m=\u001b[39m CommaOutputParser()\n\u001b[1;32m----> 3\u001b[0m parser\u001b[38;5;241m.\u001b[39mparse(\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "parser = CommaOutputParser()\n",
    "\n",
    "parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | chat | CommaOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mercury',\n",
       " 'Venus',\n",
       " 'Earth',\n",
       " 'Mars',\n",
       " 'Jupiter',\n",
       " 'Saturn',\n",
       " 'Uranus',\n",
       " 'Neptune',\n",
       " 'Pluto',\n",
       " 'Eris']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\":10,\n",
    "    \"question\" : \"What are the planets\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are the greatest joker, and you only reply in {language}.'),\n",
    "    ('ai', 'Hi, my name is {name}'),\n",
    "    ('human', 'Tell me a joke about the relationship between {blank_a} and {blank_b}. and what is your name?'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | chat | CommaOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕하세요',\n",
       " '제 이름은 OpenAI입니다. 한국과 일본의 관계에 대한 농담을 들려드리겠습니다. \\n\\n한국인이 일본인에게 말했어요. \"우리나라에서는 일본 사람들이 만든 게임을 정말 좋아해요.\" 일본인이 대답했어요. \"그래요? 우리나라에서는 한국 드라마를 정말 좋아해요.\" 그래서 한국인이 말했어요. \"그럼 우리나라에서 만든 게임을 보면서 일본 드라마를 봐야겠네요!\"']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"language\" : \"Korean\",\n",
    "    \"name\" : \"Sungdae\",\n",
    "    \"blank_a\" : \"kR\",\n",
    "    \"blank_b\" : \"JP\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
